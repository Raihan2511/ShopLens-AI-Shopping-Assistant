\chapter{Literature Review}
\label{chap:literature_review}


In this paper, He et al. [1] (2018) propose Mask R-CNN, an extension of Faster R-CNN for object instance segmentation. The method adds a parallel branch to predict segmentation masks for each Region of Interest (RoI) while retaining the existing branches for classification and bounding box regression. A key innovation is RoIAlign, a quantization-free layer that improves spatial alignment, leading to significant performance boosts in mask prediction. Mask R-CNN runs at 5 fps and demonstrates state-of-the-art results across multiple tasks like instance segmentation, object detection, and human pose estimation on the COCO dataset. It surpasses previous complex methods while remaining conceptually simple and flexible to train. Despite its simplicity, it achieves high accuracy without bells and whistles. The model is scalable and can be adapted for other instance-level tasks. The paper emphasizes that separating mask and class predictions and maintaining exact spatial alignment are crucial for performance. Overall, Mask R-CNN sets a solid baseline for future instance segmentation research.


In this paper, Minaee et al. [2] (2020) provide a comprehensive survey on deep learning-based image segmentation methods. They cover a wide range of approaches including Fully Convolutional Networks (FCNs), encoder-decoder architectures like U-Net, multi-scale models, recurrent networks, attention-based models, and generative adversarial approaches. The survey discusses how deep learning has enabled breakthroughs in both semantic and instance segmentation, replacing traditional techniques like thresholding and region growing. Key architectural choices, loss functions, datasets, and evaluation metrics are thoroughly analyzed. The paper also presents comparative results on various benchmarks like PASCAL VOC, Cityscapes, and COCO. Finally, the authors highlight current challenges such as dealing with limited labeled data, fine-grained boundaries, and computational costs. They propose future directions like leveraging unsupervised learning and enhancing generalization. This survey acts as a fundamental resource for researchers aiming to develop or benchmark deep learning-based segmentation systems.


In this paper, Dosovitskiy et al. [3] (2021) propose Vision Transformer (ViT), applying pure Transformers to image classification tasks without relying on convolutional layers. The approach splits images into fixed-size patches, embeds them linearly, and feeds them into a standard Transformer encoder. Unlike CNNs, ViT does not inherently capture locality or translation equivariance, but with sufficient pretraining on large datasets like ImageNet-21k or JFT-300M, it achieves competitive or superior performance compared to state-of-the-art CNNs. ViT attains 88.55\% top-1 accuracy on ImageNet and 94.55\% on CIFAR-100. The paper emphasizes that larger scale datasets and simple architectures without inductive biases outperform heavily engineered convolutional designs when enough data is available. Vision Transformer marks a paradigm shift, demonstrating that Transformer-based models can excel in vision tasks purely based on large-scale pretraining.


In this paper, Fang et al. [4] (2021) introduce YOLOS, a series of object detectors based on the canonical Vision Transformer (ViT) architecture with minimal modifications. YOLOS adapts ViT for object detection by introducing learnable detection tokens ([DET] tokens) and training with a set prediction loss without region-based CNN components. Despite lacking inductive biases like locality and hierarchical structure, YOLOS achieves competitive object detection performance on COCO when pre-trained only on ImageNet-1k. The simplicity of YOLOS highlights that pure Transformer models can transfer from classification to object detection tasks effectively. The paper also discusses the sensitivity of YOLOS to pretraining schemes and suggests that improvements in large-scale training could further enhance its performance. YOLOS contributes to the growing trend of simplifying vision models by relying on Transformer architectures.


In this paper, Nakata et al. [5] (2022) propose a novel kNN-based image classification system that stores extracted feature maps, labels, and original images externally rather than embedding knowledge within model parameters. Their system uses external high-capacity storage like a database and refers to it for inference, thus avoiding the need for fine-tuning when new data is added. This approach mitigates catastrophic forgetting in continual learning scenarios. Using a pretrained feature extractor and a simple kNN classifier, the system achieves competitive results, like 79.8\% top-1 accuracy on ImageNet without further fine-tuning and 90.8\% on Split CIFAR-100 in incremental learning. Additionally, the kNN approach enhances explainability by allowing users to trace back predictions to specific examples. The paper challenges traditional model-centric classification paradigms by demonstrating the effectiveness and practicality of data-driven, retrieval-based inference for large-scale and continual learning tasks.


In this paper, Patel [6] (2024) reviews traditional and deep learning-based techniques for image segmentation. Traditional methods discussed include thresholding, region growing, edge detection, and clustering, which are based on simple low-level features like color, intensity, and texture. The paper transitions into the modern era by describing deep learning-based methods like FCN, U-Net, DeepLab, and Mask R-CNN, which leverage Convolutional Neural Networks (CNNs) for high-accuracy segmentation tasks. Patel also highlights the challenges faced by segmentation algorithms, such as dealing with noise, illumination variations, and occlusions. Evaluation metrics like precision, recall, IoU, and mAP are discussed to assess segmentation performance. The review concludes by emphasizing that despite progress, image segmentation still faces obstacles like complex object structures and the need for robust models, keeping it an active area of research.